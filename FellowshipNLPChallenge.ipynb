{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NasrinGitHub/02-KaggleProjs/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HmQXn13Si1q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aanLznsjkwka"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA and Preprocessing the data"
      ],
      "metadata": {
        "id": "aY3H2uRLWMGr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cAl-xvbfgERM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c1036055-652d-4691-93e9-7937d30a32ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43048d4a-861d-4178-af6d-ea740c5d10db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43048d4a-861d-4178-af6d-ea740c5d10db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43048d4a-861d-4178-af6d-ea740c5d10db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43048d4a-861d-4178-af6d-ea740c5d10db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c208f1bc-a05c-4d7e-a4e4-0da7e8c48763\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c208f1bc-a05c-4d7e-a4e4-0da7e8c48763')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c208f1bc-a05c-4d7e-a4e4-0da7e8c48763 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2c8869e0-9cdc-4647-90cf-38fc988e9c8d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2c8869e0-9cdc-4647-90cf-38fc988e9c8d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv(\"IMDB_Dataset.csv\",engine=\"python\", on_bad_lines='skip' )\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dups= df[df.duplicated()].review\n",
        "dups"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1RzMto75aaq",
        "outputId": "6ea18e19-da43-4055-e455-05a0525aae72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3537     Quite what the producers of this appalling ada...\n",
              "3769     My favourite police series of all time turns t...\n",
              "4391     Beautiful film, pure Cassavetes style. Gena Ro...\n",
              "6352     If you liked the Grinch movie... go watch that...\n",
              "6479     I want very much to believe that the above quo...\n",
              "                               ...                        \n",
              "49912    This is an incredible piece of drama and power...\n",
              "49950    This was a very brief episode that appeared in...\n",
              "49984    Hello it is I Derrick Cannon and I welcome you...\n",
              "49986    This movie is a disgrace to the Major League F...\n",
              "49991    Les Visiteurs, the first movie about the medie...\n",
              "Name: review, Length: 418, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#allDups = df[df[\"review\"].isin(dups)]\n",
        "#allDups.groupby(\"review\")['sentiment'].apply(list)"
      ],
      "metadata": {
        "id": "yIgXTNOv6M23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.drop_duplicates()\n",
        "data.shape"
      ],
      "metadata": {
        "id": "iH4HlbMM5Dqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba13948b-fd45-494b-bec8-27717e197f14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49582, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktRQBenOSURF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhcwnuDYgXEC",
        "outputId": "c5bbc5f3-58d6-4185-a352-26379821b29c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAMuuaQIgcTJ",
        "outputId": "6954abc0-79c6-46a4-c52d-f52a2d804ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       49582\n",
              "sentiment        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPj1O0Q7gcdw",
        "outputId": "b8d8509e-ac1f-409b-9577-f6adb47731eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    24884\n",
              "negative    24698\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer #lemmatization purpose\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "# Preprocess function to clean text\n",
        "def preprocess_text(text):\n",
        "    #text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stopwords.words('english')]\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "data['review'] = data['review'].apply(preprocess_text)\n",
        "reviews = data['review'].values\n",
        "sentiments = data['sentiment'].values\n",
        "\n",
        "# Convert sentiments to binary values\n",
        "labels = np.array([1 if sentiment == 'positive' else 0 for sentiment in sentiments])\n"
      ],
      "metadata": {
        "id": "sV7XHiU4JFrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6452f0c0-c793-4043-806f-068eaf1a0a50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data\n",
        "train_reviews, test_reviews, train_labels, test_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "06-D7hKcyCR1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBJeZEC3f_iK"
      },
      "source": [
        "# Using CountVectorizer and RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J3Cm6nKZg8Fb"
      },
      "outputs": [],
      "source": [
        "## Use BAG OF WORDS for Vectorization\n",
        "countvector=CountVectorizer(ngram_range=(2,2))\n",
        "traindataset=countvector.fit_transform(train_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_cISre0ohTqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e25972e1-ddee-4309-9263-f6c3c8176963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Train RandomForest Classifier\n",
        "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')\n",
        "randomclassifier.fit(traindataset,train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cBOQRdz3hTwd"
      },
      "outputs": [],
      "source": [
        "#test the mdoel\n",
        "test_dataset = countvector.transform(test_reviews)\n",
        "predictions = randomclassifier.predict(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "28ZXeskchTzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22c9c14-2ec7-458c-cd48-53c99e8235da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3653 1286]\n",
            " [ 610 4368]]\n",
            "0.8088131491378441\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.74      0.79      4939\n",
            "           1       0.77      0.88      0.82      4978\n",
            "\n",
            "    accuracy                           0.81      9917\n",
            "   macro avg       0.81      0.81      0.81      9917\n",
            "weighted avg       0.81      0.81      0.81      9917\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Check accuracy\n",
        "matrix=confusion_matrix(test_labels,predictions)\n",
        "print(matrix)\n",
        "score=accuracy_score(test_labels,predictions)\n",
        "print(score)\n",
        "report=classification_report(test_labels,predictions)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hicDssrGfd9y"
      },
      "source": [
        "# Using Tokenizer and Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tl1tNE2wSUka"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Preprocess the Data\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "embedding_dim = 100\n",
        "trunc_type = 'post'\n",
        "oov_tok = \"<OOV>\""
      ],
      "metadata": {
        "id": "WQBnSUvLaQrV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbthBW_yfUBD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wqw3OqQLWwKL"
      },
      "outputs": [],
      "source": [
        "# Tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Tokenize and create pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, truncating=trunc_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPz58frCIzCU",
        "outputId": "4a7b5f7e-2cae-44bf-d3ad-2b9f4b630a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1240/1240 [==============================] - 215s 171ms/step - loss: 0.3349 - accuracy: 0.8561 - val_loss: 0.3241 - val_accuracy: 0.8756\n",
            "Epoch 2/5\n",
            "1240/1240 [==============================] - 138s 111ms/step - loss: 0.2191 - accuracy: 0.9165 - val_loss: 0.3111 - val_accuracy: 0.8769\n",
            "Epoch 3/5\n",
            "1240/1240 [==============================] - 121s 98ms/step - loss: 0.1595 - accuracy: 0.9414 - val_loss: 0.3230 - val_accuracy: 0.8691\n",
            "Epoch 4/5\n",
            "1240/1240 [==============================] - 116s 94ms/step - loss: 0.1164 - accuracy: 0.9589 - val_loss: 0.4192 - val_accuracy: 0.8687\n",
            "Epoch 5/5\n",
            "1240/1240 [==============================] - 115s 93ms/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.4130 - val_accuracy: 0.8743\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Model definition\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 5\n",
        "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(test_padded, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmH8mDZ1fAR6"
      },
      "source": [
        "# Using Word2Vec model and LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "GcP2U129M4oS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ohRHsSeLiOMl"
      },
      "outputs": [],
      "source": [
        "# Tokenize the reviews for Word2Vec\n",
        "train_tokens = [review.split() for review in train_reviews]\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=train_tokens, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create a word index dictionary\n",
        "word_index = {word: index for index, word in enumerate(word2vec_model.wv.index_to_key)}\n",
        "\n",
        "# Function to convert texts to sequences of word vectors\n",
        "def text_to_sequence(text, word2vec_model, word_index, max_length):\n",
        "    sequence = []\n",
        "    for word in text.split():\n",
        "        if word in word_index:\n",
        "            sequence.append(word2vec_model.wv[word])\n",
        "        else:\n",
        "            sequence.append(np.zeros(word2vec_model.vector_size))\n",
        "    if len(sequence) < max_length:\n",
        "        sequence += [np.zeros(word2vec_model.vector_size)] * (max_length - len(sequence))\n",
        "    else:\n",
        "        sequence = sequence[:max_length]\n",
        "    return np.array(sequence)\n",
        "\n",
        "# Convert all reviews to sequences of word vectors\n",
        "#max_length = 100\n",
        "train_sequences = np.array([text_to_sequence(review, word2vec_model, word_index, max_length) for review in train_reviews])\n",
        "test_sequences = np.array([text_to_sequence(review, word2vec_model, word_index, max_length) for review in test_reviews])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tUJoCgRpiOZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cb29dc-1a91-427c-9828-3662c13809e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "620/620 [==============================] - 15s 15ms/step - loss: 0.4449 - accuracy: 0.8005 - val_loss: 0.3545 - val_accuracy: 0.8488\n",
            "Epoch 2/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.3433 - accuracy: 0.8554 - val_loss: 0.3351 - val_accuracy: 0.8590\n",
            "Epoch 3/10\n",
            "620/620 [==============================] - 7s 12ms/step - loss: 0.3218 - accuracy: 0.8654 - val_loss: 0.3221 - val_accuracy: 0.8623\n",
            "Epoch 4/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.3029 - accuracy: 0.8760 - val_loss: 0.3143 - val_accuracy: 0.8672\n",
            "Epoch 5/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.2879 - accuracy: 0.8833 - val_loss: 0.3198 - val_accuracy: 0.8652\n",
            "Epoch 6/10\n",
            "620/620 [==============================] - 7s 12ms/step - loss: 0.2751 - accuracy: 0.8882 - val_loss: 0.3224 - val_accuracy: 0.8677\n",
            "Epoch 7/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.2588 - accuracy: 0.8967 - val_loss: 0.3120 - val_accuracy: 0.8654\n",
            "Epoch 8/10\n",
            "620/620 [==============================] - 7s 12ms/step - loss: 0.2452 - accuracy: 0.9022 - val_loss: 0.3311 - val_accuracy: 0.8662\n",
            "Epoch 9/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.2257 - accuracy: 0.9112 - val_loss: 0.3301 - val_accuracy: 0.8625\n",
            "Epoch 10/10\n",
            "620/620 [==============================] - 8s 12ms/step - loss: 0.2098 - accuracy: 0.9192 - val_loss: 0.3534 - val_accuracy: 0.8635\n",
            "310/310 [==============================] - 2s 5ms/step - loss: 0.3534 - accuracy: 0.8635\n",
            "Test Accuracy: 0.8634667992591858\n"
          ]
        }
      ],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(max_length, word2vec_model.vector_size), return_sequences=True),\n",
        "    LSTM(32),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_sequences, train_labels, epochs=10, batch_size=64, validation_data=(test_sequences, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_sequences, test_labels)\n",
        "print(f'Test Accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSXndaYOfpfy"
      },
      "source": [
        "# Using Fine tunned Word2Vec, Embedding and  Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BDZi97Z4mJWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c6b0ea-065f-4298-fb99-f3fbbc4bcc32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X7rO38_BI6EE"
      },
      "outputs": [],
      "source": [
        "# Test & Train size\n",
        "TEST_SIZE = 0.3\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = reviews"
      ],
      "metadata": {
        "id": "bH0pRXD9d1sW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "diUeUqrImlw2"
      },
      "outputs": [],
      "source": [
        "def generate_word2vec_tokens(list_of_sentences):\n",
        "  sentences = []\n",
        "  for s in list_of_sentences:\n",
        "    sentences.append(s.split())\n",
        "  return sentences\n",
        "\n",
        "def generate_word2vec(sentences):\n",
        "  w2v_model=gensim.models.Word2Vec(sentences=sentences,vector_size=embedding_dim,window=10,min_count=1)\n",
        "  w2v_model.train(sentences,epochs=10,total_examples=len(sentences))\n",
        "  return w2v_model\n",
        "\n",
        "def save_word2vec(word2vec_model, model_name):\n",
        "  word2vec_model.wv.save_word2vec_format(model_name, binary=True)\n",
        "\n",
        "def load_word2vec(model_name):\n",
        "  loaded_model = gensim.models.KeyedVectors.load_word2vec_format(model_name, binary=True)\n",
        "  return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjWXeiLvmbUn",
        "outputId": "8c2e0c4b-7c9c-42a0-a0c4-d83e75f1723d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        }
      ],
      "source": [
        "ss = generate_word2vec_tokens(corpus)\n",
        "word2vec_model  = generate_word2vec(ss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9RCuhzSr7yzc"
      },
      "outputs": [],
      "source": [
        "save_word2vec(word2vec_model , 'word2vec.bin')\n",
        "\n",
        "w2v_model = load_word2vec('word2vec.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jEHfQinldRXf"
      },
      "outputs": [],
      "source": [
        "def apply_tokenizer(data):\n",
        "  tok = Tokenizer(num_words = vocab_size)\n",
        "  tok.fit_on_texts(data)\n",
        "  encoded_data = tok.texts_to_sequences(data)\n",
        "  return [tok, encoded_data]\n",
        "\n",
        "def apply_padding(data):\n",
        "  pad_data = pad_sequences(data, maxlen=max_length)\n",
        "  print(\"New Dimensions: \", pad_data.shape)\n",
        "  return pad_data\n",
        "\n",
        "def generate_embedded_matrix(tok, w2v_model):\n",
        "  embed_matrix=np.zeros(shape=(vocab_size,embedding_dim))\n",
        "  for word,i in tok.word_index.items():\n",
        "    if i < vocab_size and  word in w2v_model.key_to_index:\n",
        "      embed_vector=w2v_model.get_vector(word)\n",
        "      if embed_vector is not None:  # word is in the vocabulary learned by the w2v model\n",
        "        embed_matrix[i]=embed_vector\n",
        "  return embed_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKIbm6Umdigq",
        "outputId": "4a777b26-5d0e-4a3b-c94f-ce1b5aed7510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Dimensions:  (49582, 500)\n"
          ]
        }
      ],
      "source": [
        "tok, encoded_corpus = apply_tokenizer(corpus)\n",
        "\n",
        "embed_matrix = generate_embedded_matrix(tok, w2v_model)\n",
        "\n",
        "pad_corpus = apply_padding(encoded_corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7E_xRejxdvky"
      },
      "outputs": [],
      "source": [
        "X_final=pad_corpus\n",
        "y_final= np.array(sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zKBXliRe-uQL"
      },
      "outputs": [],
      "source": [
        "y = np.array([1 if y == 'positive' else 0 for y in y_final])\n",
        "y_final = np.asarray(y).astype(\"float64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ges4UWGD_KSx",
        "outputId": "0e9a36fa-21b8-4c2d-e66b-a418f5729202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1kn_h38dw6d",
        "outputId": "c4d4d867-58a7-4367-faac-75edd5a4da71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49582, 500), (49582,))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "X_final.shape,y_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uDC1rNbedzpi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=TEST_SIZE, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bfrqb5fyd6Oq"
      },
      "outputs": [],
      "source": [
        "# Create Model\n",
        "def create_model(MODEL):\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size,output_dim=embedding_dim,input_length=max_length,embeddings_initializer=Constant(embed_matrix)))\n",
        "  model.add(Dense(256))\n",
        "  model.add(Dropout(0.05))\n",
        "  model.add(MODEL)\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "# Train Model\n",
        "def train_model(MODEL, x_train, y_train):\n",
        "  earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "  MODEL.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      validation_split=0.1,\n",
        "      epochs=EPOCHS,\n",
        "      shuffle=True,\n",
        "      batch_size=BATCH_SIZE\n",
        "      ,callbacks=[earlystop]\n",
        "  )\n",
        "\n",
        "def generate_classification_report(y_test, y_pred):\n",
        "  print(classification_report(y_test,y_pred))\n",
        "\n",
        "# Test Model\n",
        "def test_model(MODEL, model_name, x_test, y_test):\n",
        "  y_pred=MODEL.predict(x_test)\n",
        "  y_pred=np.where(y_pred >= 0.5, 1,0)\n",
        "  score = accuracy_score(y_pred,y_test)\n",
        "  print('Model Accuracy: ',score)\n",
        "  print(\"\\n\\nClassification Report\")\n",
        "  generate_classification_report(y_test,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa7fptdreKli",
        "outputId": "edc295fa-7d8c-45e9-c051-97c42492f19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 100)          1000000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 500, 256)          25856     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500, 256)          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 512)               1050624   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2076993 (7.92 MB)\n",
            "Trainable params: 2076993 (7.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "447/447 [==============================] - 73s 155ms/step - loss: 0.3403 - accuracy: 0.8558 - val_loss: 0.2889 - val_accuracy: 0.8834\n",
            "Epoch 2/5\n",
            "447/447 [==============================] - 45s 100ms/step - loss: 0.2497 - accuracy: 0.9003 - val_loss: 0.2795 - val_accuracy: 0.8840\n",
            "Epoch 3/5\n",
            "447/447 [==============================] - 34s 75ms/step - loss: 0.2136 - accuracy: 0.9156 - val_loss: 0.2479 - val_accuracy: 0.9006\n",
            "Epoch 4/5\n",
            "447/447 [==============================] - 26s 59ms/step - loss: 0.1735 - accuracy: 0.9323 - val_loss: 0.2732 - val_accuracy: 0.8923\n",
            "Epoch 5/5\n",
            "447/447 [==============================] - 25s 55ms/step - loss: 0.1412 - accuracy: 0.9466 - val_loss: 0.2889 - val_accuracy: 0.8949\n",
            "465/465 [==============================] - 7s 14ms/step\n",
            "Model Accuracy:  0.959327731092437\n",
            "\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.97      0.96      7404\n",
            "         1.0       0.97      0.95      0.96      7471\n",
            "\n",
            "    accuracy                           0.96     14875\n",
            "   macro avg       0.96      0.96      0.96     14875\n",
            "weighted avg       0.96      0.96      0.96     14875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bi_lstm = create_model(Bidirectional(LSTM(256)))\n",
        "train_model(bi_lstm, X_final, y_final)\n",
        "test_model(bi_lstm,\"Bidirectional_LSTM_RNN\", X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqceyTAC-kQd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyOuj8lt/zBj8ZeOT9Fegag1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
